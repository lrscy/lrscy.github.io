---
title: 机器学习西瓜书查缺补漏
tags: [Machine Learning]
categories: [Machine Learning]
mathjax: True

---

本文只记录一些读西瓜书时候没有完全掌握的知识点和概念，用于之后复习回顾。

<!--more-->

奥卡姆剃刀：若有多个假设与观察一致，则选择最简单的那个。“简单”的定义并不简单，需要具体问题具体分析。

没有免费的午餐：无论算法多聪明或笨拙，其期望是相同的。前提是所有问题出现机会相同、或所有问题同等重要。

Bootstrapping：给定包含$m$个样本的数聚集$D$，我们对它进行采样生成数聚集$D'$：每次随机从$D$中挑选一个样本并拷入$D'$中，然后再将其放回$D$，重复$m$次后即得到包含$m$个样本的数聚集$D'$。做一个简单的估计，样本在$m$次采样中始终不被采到的概率是$(1-\frac{1}{m})^m$，取极限是：
$$
\lim\_{x\to\infty} (1-\frac{1}{m})^m=\frac{1}{e}\approx0.368
$$

odd: $\frac{y}{1-y}$反映了$x$作为正例的相对可能性。

LDA
二分类：
$$
\begin{align}
J &= \frac{\omega^TS\_b\omega}{\omega^TS\_\omega\omega} \\\\
S\_\omega &= \sum\_0 + \sum\_1 \\\\
&= \sum\_{x\inX\_0}(x-\mu\_0)(x-\mu\_0)^T + \sum\_{x\inX\_1}(x-\mu\_1)(x-\mu\_1)^T \\\\
S\_b &= (\mu\_0-\mu\_1)(\mu\_0-\mu\_1)^T \\\\
\omega &= S\_\omega^{-1}(\mu\_0-\mu\_1)
\end{align}
$$

纠错输出码

决策树：预留出测试集
- 预剪枝：分树时候计算是否比现在更优，贪心
- 后减枝：生成全树后减枝，减后是否比减前更优

神经网络跳出局部最小：
- 多组初始化
- 模拟退火，每一步以一定概率接受“次优解”，概率逐步降低依确保稳定
- 随机梯度下降

RBF网络
$$
\begin{align}
\phi(x) &= \sum\_{i=1}^q\omega\_i\ro(x,c\_i) \\\\
\ro(x,c\_i) &= e^{-\beta\_i\(\vert \vert\)x-c\_i\(\vert \vert\)^2}
\end{align}
$$
$q$为隐层神经元个数，$c\_i$和$\omega\_i$分别是第i个神经元对应的中心和权重。确定中心的方法常用的有随机采样和聚类。

ART网络：竞争型学习代表
可进行增量学习和在线学习

SOM网络：可用于降维。为每个神经元找到合适的权向量，在低维空间保持拓扑结构。

Boltzmann机
整个图就是个最大团。一般使用受限Boltzmann机。
